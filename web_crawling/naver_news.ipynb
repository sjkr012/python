{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Selenium으로 \n",
    "######### naver 크롤링 연습(1): 검색 후 뉴스 첫 페이지의 텍스트 가져오기\n",
    "######### 학습용으로 크롤링 한 것이나 문제가 될 시 바로 삭제하겠습니다\n",
    "\n",
    "# imports\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 셀레니움 imports\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "# content = h.find_element_by_css_selector('dl > dd:nth-child(1)').text li:nth-child(3) 이건 안되고 elements[1]은 됨? 연구 ㄱ\n",
    "\n",
    "def save_to_pickle(df,search_title):\n",
    "    pickle.dump(df, open('./data/{}_df.pkl'.format(search_title),'wb'))\n",
    "    print('저장완료')\n",
    "\n",
    "def get_all_news_elements():\n",
    "    df = pd.DataFrame(columns=['title', 'author', 'content'])\n",
    "    \n",
    "    lists = driver.find_elements_by_css_selector('#main_pack > div.news.mynews.section._prs_nws > ul.type01 > li')\n",
    "    for lst in lists:\n",
    "        try: \n",
    "            # 데이터프레임에 추가하기\n",
    "            df.loc[len(df)] = {\n",
    "                # 긁어모아 df에 저장하기\n",
    "                'title':lst.find_element_by_css_selector('dl > dt > a').get_attribute(\"title\"),\n",
    "                'author':lst.find_element_by_css_selector('dl > dd.txt_inline > span._sp_each_source').text,\n",
    "                'content':lst.find_elements_by_css_selector('dl > dd')[1].text\n",
    "            }   \n",
    "\n",
    "        except Exception as e:\n",
    "            print('텍스트 가져오기 에러')\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "    print(df)\n",
    "    print(\"끝\",\"꼴\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    # driver.find_elements_by_class_name('_sp_each_url._sp_each_title').get_attribute(\"title\")\n",
    "def crawl(search):\n",
    "    time.sleep(2) # 잠시 기다리기\n",
    "    # div가 여러개일 경우 div.classname으로 명시해줄것\n",
    "    \n",
    "    # 검색창 클릭\n",
    "    driver.find_element_by_css_selector('#nx_search_form > fieldset > div.greenbox > span > input').click()\n",
    "    # xpath 용으로 하나 ㅎㅎ\n",
    "    # driver.find_element_by_xpath('//*[@id=\"nx_search_form\"]/fieldset/div.greenbox/span/input').click()\n",
    "    \n",
    "    # 검색어 입력\n",
    "    driver.find_element_by_css_selector('#nx_query').send_keys(search)\n",
    "    # 검색 버튼 클릭\n",
    "    driver.find_element_by_css_selector('#nx_search_form > fieldset > button').click() \n",
    "    \n",
    "    # df 받기\n",
    "    news_df = get_all_news_elements()\n",
    "    # pickle 파일이름\n",
    "    s_title = '네이버_' + search\n",
    "    # 저장\n",
    "    save_to_pickle(news_df,s_title)\n",
    "\n",
    "\n",
    "\n",
    "def news():\n",
    "    print('네이버 뉴스 검색 크롤링 연습입니다. 알맞는 형태의 파일을 올려주세요')\n",
    "    \n",
    "    search = input('검색어를 설정해주세요:  ')\n",
    "    #start = input('시작날짜를 입력해주세요 [ex)2020.07.22]:  ')\n",
    "    #end = input('종료할 날짜를 입력해주세요 [ex)2020.07.22]:  ')\n",
    "    #search = '물병'\n",
    "    crawl(search)\n",
    "    \n",
    "    \n",
    "# Chrome driver 부르기\n",
    "driver = webdriver.Chrome('c:/cdriver/chromedriver.exe')\n",
    "driver.implicitly_wait(3) # \n",
    "url = 'https://search.naver.com/search.naver?where=news/'\n",
    "driver.get(url)\n",
    "\n",
    "# sleep: 프로세스 자체를 지연 (무조건 지연) \n",
    "# implicitly_wait : 파싱 시간을 기다려주는 메소드\n",
    "# (wait 해주지 않으면, 브라우저에서 바로 파싱이 되지 않으면 에러 후 종료가 됨)\n",
    "# (즉, 로딩 시간을 기다려 주지 않는 것)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 시작\n",
    "news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled file 열기\n",
    "df = pickle.load(open('./data/네이버_물병_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show five rows from the end\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
